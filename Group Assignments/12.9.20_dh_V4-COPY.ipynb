{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Assignment Four AG and DH- this notebook is to export the dfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sodapy import Socrata\n",
    "import folium\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in EJSM df and make string of tracts to be named\n",
    "df = pd.read_csv(\n",
    "'Data/EJSM_Scores/EJSM_Scores (1).csv' ,\n",
    "dtype={\n",
    "    'Tract_1':str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('file.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add number zero leading the FIPS code for merging the data with the census tract data\n",
    "df['Tract_1'] = df['Tract_1'].str.zfill(11)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import 2012 census data\n",
    "tracts=gpd.read_file('Data/CensusData2012/census-tracts-2012.geojson')\n",
    "print(tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List column names \n",
    "list(tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select unwanted columns\n",
    "columns_to_drop = ['set','kind','resource_uri','metadata']\n",
    "#read columns \n",
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns from tracts data\n",
    "tracts = tracts.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show tracts info\n",
    "tracts.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the FIPS code and geometry columns to match with the EJSM data\n",
    "tracts = tracts[['name','geometry']]\n",
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show isolated columns - COULD ADD tracts.columns\n",
    "tracts.columns = ['FIPS','geometry']\n",
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Tract_1 to FIPS\n",
    "df.columns = ['OBJECTID',\n",
    " 'FIPS',\n",
    " 'CIscore',\n",
    " 'HazScore',\n",
    " 'HealthScore',\n",
    " 'SVscore',\n",
    " 'CCVscore',\n",
    " 'Shape__Area',\n",
    " 'Shape__Length']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section will explore the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List new df columns\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data on the same object FIPS\n",
    "tracts_ejsm=tracts.merge(df,on=\"FIPS\")\n",
    "#Show merge with census data\n",
    "tracts_ejsm.head()\n",
    "tracts_ejsm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_ejsm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tracts_ejsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted df to geojson \n",
    "df.to_file(\"tracts_ejsm.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_ejsm.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last time we see EJSM multipolygon data\n",
    "tracts_ejsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NULL- convert csv\n",
    "#df = tracts_ejsm.to_csv('Mangonadas\\Data\\tracts_ejsm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NULLread in csv- READ AS RACTS IN DATA FOLDER\n",
    "#df = pd.read_csv(\n",
    "#'Mangonadas\\Data\\tracts_ejsm.csv',\n",
    "#dtype={\n",
    "#    'Tract_1':str\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe stats by proximity to hazard score\n",
    "tracts_ejsm['CIscore'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for cumulative impact score\n",
    "tracts_ejsm['CIscore'].plot.hist(bins=50),\n",
    "plt.xlabel('Cumulative Impact Scores')\n",
    "plt.ylabel('Frequency'),\n",
    "plt.savefig('CIscore.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for proximity to hazard score. It is grouped by the number of occurences. \n",
    "#Our not so great graph! Seeing this bar chart intrigued us to durther explore the variations between census tracts.\n",
    "tracts_ejsm['HazScore'].plot.hist(bins=50)\n",
    "plt.xlabel('Proximity to Hazards')\n",
    "plt.ylabel('Frequecy'),\n",
    "plt.savefig('HazScore_bar.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s unclear why the hazard score data is not distributed the same way as the cumulative impact score data. We wondered if it was because we had miswritten it or if the hazard occurrences were not visible on this bar graph. What is apparent is the average cumulative impact score of LA lying somewhere between 10.5-12.5. The cumulative score considers all the scores identified from the dataset included proximity to hazards, social vulnerability, climate vulnerability, and health vulnerability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New object to show the sorted data- these are the top polluted census tracts. The census tracts that are shown as being the most polluted are also the most socially vulnerable.\n",
    "tracts_ejsm_sorted = tracts_ejsm.sort_values(by='CIscore',ascending = False)\n",
    "tracts_ejsm_sorted[['FIPS','CIscore','HazScore','SVscore']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot represents the proximity to environmental hazards score by equal intervals \n",
    "#We can see that the most polluted areas are in south central LA county \n",
    "tracts_ejsm.plot(figsize=(24,20),\n",
    "                 column='HazScore',\n",
    "                 legend=True, \n",
    "                 scheme='equal_interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot represents the cumulative impact scores separated by natural breaks\n",
    "#The map shows increased variation because of the integrated scores\n",
    "tracts_ejsm.plot(figsize=(24,20),\n",
    "                 column='CIscore',\n",
    "                 legend=True, \n",
    "                 scheme='NaturalBreaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Chloropleth map provides us with a background map that will kick off the rest of our work. We chose hazard scores because while the cumulative impact was meaningful, we wanted to focus on a standard that could be more decisively measured (proximity to environmental hazards in the form of pollutants) rather than other measurements. Measurements include a social vulnerability that could be more skewed based on indicators defined by the source (in this case, USC/Occidental College). For example, although poverty and policing can be linked, we wanted to see if sites that were contaminated or close to toxic sites (such as Exide) would have a significant relationship to policing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "There is a problem with the way you are importing the data. You have a limit of 10,000 records (this can be upped to 50,000), and you do not sort the data in any way. The resulting data is a subset of records of the total.\n",
    "    \n",
    "Consider instead to specify a date range and a query that makes the data fall under the 50000 record limit.\n",
    "\n",
    "I provide an example below (df2) for your reference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing our arrest 2020 data using an API\n",
    "client = Socrata(\"data.lacity.org\", None)\n",
    "results = client.get(\"amvf-fr72\", \n",
    "                     limit=50000,\n",
    "                     where = \"(arst_date between '2020-01-01T00:00:00' and '2020-10-30T00:00:00') AND (grp_description in ('Aggravated Assault','Miscellaneous Other Violations','Driving Under Influence','Other Assaults','Narcotic Drug Laws'))\",\n",
    "                     order='arst_date desc')\n",
    "df =pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "This example limits the import to certain crime types (look at the list within the where statement). Adjust these as necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample data to check for inconsistencies\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get description of arrest data \n",
    "df.grp_description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining all data types in the df for floats\n",
    "df.lon = df.lon.astype('float')\n",
    "df.lat = df.lat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "As you can see, the plot below paints a different picture.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plotly bar graph to examine the total arrests by LAPD in 2020\n",
    "px.bar(df,\n",
    "       x='arst_date',\n",
    "       title='LAPD Arrests in 2020',\n",
    "       labels={'arst_date':'Arrest date','counts':'Number of arrests'}\n",
    "      ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been a graph circulating, but it’s interesting to note how arrests boom in the summer months and the moments leading up to it due to the uprisings. What would these look like across time? When hearing about the ‘92 uprising, a familiar anecdote is how heat and power shortages aggravated communities already frustrated and fed up with the policing system. While it’s hard to test this, it’s important to note how many people, particularly folks of color, we’re stuck at home due to quarantine during summer, and many lacked air conditioning (or income to pay for utilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Index arrest charge value counts\n",
    "arrest_by_charge = df.grp_description.value_counts().reset_index()\n",
    "arrest_by_charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Again, these numbers will change with a more accurate import.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Index arrest charge value counts\n",
    "arrest_by_charge = df.grp_description.value_counts().reset_index()\n",
    "arrest_by_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure geometry for crime geodataframe\n",
    "crime = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "crime.drop(crime[crime.lon==0].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot of crime data\n",
    "crime.plot(figsize=(12,12),color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add base from tracts data\n",
    "base = tracts_ejsm.plot(figsize=(12,10),color='gainsboro', edgecolor='white')\n",
    "\n",
    "ax = crime.plot(ax=base, color='purple', markersize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print map with within closer boundaries- IGNORE ERROR FOR NOW\n",
    "base = tracts_ejsm.plot(figsize=(12,12),color='gainsboro', edgecolor='white')\n",
    "ax = crime.plot(ax=base, marker='o', color='purple', markersize=5)\n",
    "ax.set_xlim(minx - .1, maxx + .1)\n",
    "ax.set_ylim(miny - .1, maxy + .1)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure coordinate reference system for tracts to join the two dataframes\n",
    "tracts_ejsm.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure coordinate reference system for crime\n",
    "crime.set_crs(epsg=4326, inplace=True)\n",
    "crime.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join tracts_ejsm and crime data\n",
    "join = gpd.sjoin(tracts_ejsm,\n",
    "                 crime,\n",
    "                 how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data from join\n",
    "df = pd.DataFrame(join,columns=['arst_date','rpt_id','grp_description','arst_typ_cd','HazScore','CIscore','FIPS','lat','lon','geometry'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subset of the joined dataframes \n",
    "#We are keeping these columns because our analysis focuses on the HazScore and description of the charges\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we follow Yoh’s steps more closely, but the aggravated arrests don’t tell us much. We’re trying to figure out crimes linked explicitly to environmental hazards. For now, we want to keep this large dataset because we want to be able to pick them out later depending on what crimes we want to analyze in the nexus with environmental hazards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the tracts with the highest number of arrests. We included this as a priliminary step to mapping the full counts. \n",
    "crime_by_tracts = join.FIPS.value_counts().rename_axis('Tract').reset_index(name='crime_count')\n",
    "crime_by_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This is a visualization to compare the amount of arrests in different census tracts\n",
    "crime_by_tracts[:50].plot.bar(figsize=(20,8),x='Tract',y='crime_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar graph tells us the crime by census tract, but we can only guess what that is. It would be useful to bring this into the function, but we’re looking for a better way of organizing and visualizing the data. Instead of looking at specific census tracts themselves, our goal is to understand the interconnected relationship between proximity to hazards (such as pollution) and seeing what charges the police are giving people in that area. Surprisingly, the census tract with the most crimes (06037980028) is the one belonging to the airport and in between the Chevron Oil Refinery and the Ballon Wetlands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grouped data by the description of arrest. Here, the FIPS out of order because we are descibing a full count of charge descriptions. \n",
    "df.groupby(['grp_description']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Group data by the FIPS code to explore the meaning of the counts in each census tract. \n",
    "df.groupby(['FIPS']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is grouped for counts of reports in tracts. \n",
    "df_grouped=df.groupby(['FIPS','grp_description','lat','lon','arst_date']).count()[['rpt_id']]\n",
    "df_grouped.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten data to prep for bar graph and reset the index to include the group values \n",
    "df_flat = df_grouped.reset_index()\n",
    "df_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how beautiful that index is. What is not shown in our flattened data frame is the amount of blood and tears (and lots of green tea caffeine) that helped us get to this point. Originally while our workflow was simple, things became more complicated as we tried to clean up our notebooks without taking away code that would serve us moving forward. This data frame allows us to see all types of crimes and arrest data across census tracts and their location. This provides us with the top-most layer for our future maps, in addition to a versatile data frame that can give temporal nuance to our maps, an attribute especially useful for the Kepler map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Modified the code below (added marker_line_width=0) to get rid of the white horizontal lines that were making the bars difficult to read.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make plotly bar graph\n",
    "fig = px.bar(df_flat,\n",
    "       x='grp_description',\n",
    "       y='rpt_id',\n",
    "       title='Description of LAPD Arrests in 2020',\n",
    "       color='grp_description',\n",
    "       labels={'grp_description':'Arrest Decription','rpt_id':'Number of Arrests'}\n",
    "      )\n",
    "fig.update_traces(marker_line_width=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. It was tricky to make sense of all these numbers, but having everything cleanly indexed would provide us more than enough for what we needed. Looking back now, we would like to have examined a larger sample, but based on our gigabyte limit on Jupyter Hub, we were unsure how far to push this. From this bar graph, it becomes clear that aggravated assault, driving under the influence, and other crimes are the largest ones. We’re trying to focus on aggravated assault, disturbing the peace, and disorderly contact, because these are the ones we believe can connect policing to proximity to hazards (the ejsm score). It’s clear that aggravated assault is the largest sample; there are significantly less for disorderly conduct and disturbing the peace. For now, we don’t know if this will affect the statistical significance of our findings later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the merged dataframe\n",
    "df_ejsm = tracts_ejsm.merge(df_flat,on=\"FIPS\")\n",
    "df_ejsm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert lat and lon to floats intergrating arrest and EJSM score data\n",
    "df_ejsm['lat'] = df_ejsm['lat'].astype(float)\n",
    "df_ejsm['lon'] = df_ejsm['lon'].astype(float)\n",
    "df_ejsm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to crs\n",
    "df_ejsm.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create basic scatter of df_ejsm_crime_tracts data with coordinate reference system\n",
    "px.scatter(df_ejsm,\n",
    "           x='lon',\n",
    "           y='lat'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring map styles using mapbox\n",
    "fig = px.scatter_mapbox(df_ejsm,\n",
    "                        lat='lat',\n",
    "                        lon='lon',\n",
    "                        mapbox_style=\"stamen-terrain\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tracts = tracts_ejsm[['FIPS','HazScore','geometry']]\n",
    "census_tracts.head()\n",
    "census_tracts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should this be 4326?\n",
    "census_tracts = census_tracts.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use census tracts and ejsm integrated layers to add base map\n",
    "ax=census_tracts.plot(figsize=(20,20), \n",
    "                      edgecolor='white',\n",
    "                      column='HazScore',\n",
    "                      alpha=0.5)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make crime GeoDataFrame\n",
    "crime = gpd.GeoDataFrame(df_flat, \n",
    "                         crs='EPSG:4326',\n",
    "                         geometry=gpd.points_from_xy(df_flat.lon, df_flat.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert crime to crs\n",
    "crime = crime.to_crs(epsg=3857)\n",
    "crime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use geometry to define area\n",
    "crime.geometry.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print total bounds\n",
    "minx, miny, maxx, maxy = crime.geometry.total_bounds\n",
    "print(minx)\n",
    "print(maxx)\n",
    "print(miny)\n",
    "print(maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure function map by census tracts as the base map\n",
    "base = census_tracts.plot(figsize=(20,20), \n",
    "                      edgecolor='white',\n",
    "                      column='HazScore',\n",
    "                      alpha=0.5)\n",
    "\n",
    "ax = crime.plot(ax=base, marker='o', color='purple', markersize=5)\n",
    "\n",
    "ax.set_xlim(minx - 7000, maxx + 7000) \n",
    "ax.set_ylim(miny - 7000, maxy + 7000)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define bounds for the map using the function\n",
    "crime.geometry.total_bounds\n",
    "minx, miny, maxx, maxy = crime.geometry.total_bounds\n",
    "print(minx)\n",
    "print(maxx)\n",
    "print(miny)\n",
    "print(maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_arrests_by_type(charge='Aggravated Assault'):\n",
    "    \n",
    "    crime_type = crime[crime.grp_description==charge]\n",
    "\n",
    "    minx, miny, maxx, maxy = crime_type.geometry.total_bounds\n",
    "    \n",
    "    arrests_in_tracts = gpd.sjoin(census_tracts,crime_type,how='right')\n",
    "\n",
    "    base = census_tracts.plot(figsize=(20,20), \n",
    "                    edgecolor='white',\n",
    "                    column='HazScore',\n",
    "                    alpha=0.5)\n",
    "\n",
    "    ax = arrests_in_tracts.plot(ax=base, \n",
    "                                    column='grp_description',\n",
    "                                    marker='o',\n",
    "                                    markersize=40, \n",
    "                                    legend=True,\n",
    "                                    cmap='tab20',\n",
    "                                    legend_kwds={\n",
    "                                       'loc': 'upper right',\n",
    "                                       'bbox_to_anchor':(1.3,1)\n",
    "                                    }                  # this puts the legend to the side\n",
    "                                )\n",
    "\n",
    "    ax.set_xlim(minx - 200, maxx + 200) # added/substracted value is to give some margin around total bounds\n",
    "    ax.set_ylim(miny - 200, maxy + 200)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    ax.set_title('Occurences of '+crime.grp_description.values[0]+' in Los Angeles',fontsize=20)\n",
    "\n",
    "    ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)\n",
    "    ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Map arrests by using the function\n",
    "map_arrests_by_type(charge='Aggravated Assault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# to explore point patterns\n",
    "from pointpats import centrography\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy\n",
    "# import that interact library\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice datadf\n",
    "map_arrests_by_type = crime[crime.grp_description== 'Aggravated Assault'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#map arrests by type info- this is a subset of crime ag-- i dont think i understand this\n",
    "map_arrests_by_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#overloaded \n",
    "# table\n",
    "#display(df[df.grp_description == 'Aggravated Assault'].head()) \n",
    "\n",
    "# map\n",
    "#ax = df[df.grp_description == 'Aggravated Assault'].plot(figsize=(9,9), markersize=1)\n",
    "\n",
    "# axis\n",
    "#ax.axis('off')\n",
    "\n",
    "# basemap\n",
    "#ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ag converted- gpd points\n",
    "df = gpd.GeoDataFrame(df, \n",
    "                     crs='EPSG:4326',\n",
    "                     geometry=gpd.points_from_xy(df.lon, df.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change df to crs (web mercator for seaborne) crs 4326?\n",
    "#df=df.to_crs('EPSG:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make x and y variables with only aggravated assault \n",
    "df['x'] = df.geometry.x\n",
    "df['y'] = df.geometry.y\n",
    "df[df.grp_description == 'Aggravated Assault'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data mini \n",
    "data_mini = df[df.grp_description.isin(['Aggravated Assault'])]\n",
    "data_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses xand y from mini\n",
    "sns.relplot(data=data_mini,\n",
    "            x='x', \n",
    "            y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive seaborne map\n",
    "@interact\n",
    "def sns_styles(style=['darkgrid', 'whitegrid', 'dark', 'white', 'ticks']):\n",
    "    # seaborn comes with themes to make them prettier\n",
    "    sns.set_style(style)\n",
    "\n",
    "    # scatterplot \n",
    "    sns.relplot(data=data_mini,\n",
    "                x='x', \n",
    "                y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find centrography of map\n",
    "mean_center = centrography.mean_center(df[['x','y']])\n",
    "med_center = centrography.euclidean_median(df[['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the mean center and median center of map\n",
    "sns.set_style('dark')\n",
    "\n",
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(df['x'], df['y'], s=0.75)\n",
    "ax.scatter(*mean_center, color='red', marker='x', label='Mean Center')\n",
    "ax.scatter(*med_center, color='limegreen', marker='o', label='Median Center')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# add a basemap\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter)\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set orientation\n",
    "major, minor, rotation = centrography.ellipse(df[['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the style without grid lines- \n",
    "sns.set_style('dark')\n",
    "\n",
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(df['x'], df['y'], s=0.75)\n",
    "ax.scatter(*mean_center, color='red', marker='x', label='Mean Center')\n",
    "ax.scatter(*med_center, color='limegreen', marker='o', label='Median Center')\n",
    "\n",
    "# Construct the standard ellipse using matplotlib\n",
    "ellipse = Ellipse(xy=mean_center, # center the ellipse on our mean center\n",
    "                  width=major*2, # centrography.ellipse only gives half the axis\n",
    "                  height=minor*2, \n",
    "                  angle = numpy.rad2deg(rotation), # Angles for this are in degrees, not radians\n",
    "                  facecolor='none', \n",
    "                  edgecolor='red', linestyle='--',\n",
    "                  label='Std. Ellipse')\n",
    "\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# add a basemap\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map displays the concentration of arrests with the median center and mean center. The ellipse provides a general idea about the concentration of charges. However, it is better to use the median for our analysis going forward to avoid the outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters show all crimes in tracts where the haz score is greater than 4\n",
    "sns.relplot(data=df[df['HazScore']>4],\n",
    "            x='x', \n",
    "            y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot describes areas where hazscores are above four. The concentrations are similar to the arrest plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Seaborne map \n",
    "g = sns.jointplot(data = df,\n",
    "                  x='x', \n",
    "                  y='y',\n",
    "                  hue='grp_description',\n",
    "                  s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seaborn plot shows the concentration of different charge types in Los Angeles. On the sides of the map, we can see how the concentrations are higher in areas closer to the center of the map. Instances of aggravated assualt are higher in central LA. Despite not having a basemap, this KDE plot is useful in renderin an overall view that describes the distribution of charges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df to gdf from hazscore per tract estimation? to normalize data?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where we had trouble with the ratio\n",
    "#ratio is lacking the multiploygon framing for base map for chloropleth \n",
    "#could be a problem without the column names named\n",
    "#problem is that the haz score is not by 1000s \n",
    "#STEPS\n",
    "#define gdf\n",
    "#figure out pop and reduce it by FIPS\n",
    "\n",
    "#code\n",
    "\n",
    "#gdf['g'] = gdf['arrests_per_HazScore']/gdf['TotalPop']*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploration with hazscore \n",
    "sns.jointplot(data=df[df['HazScore']>4],\n",
    "              x='x', \n",
    "              y='y', \n",
    "              kind='kde')\n",
    "ax.axis('off')\n",
    "\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check df \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE IS THE READ MISSING UNAMED\n",
    "\n",
    "#dftec=pd.read_csv(\n",
    "#'Mangonadas\\Data\\dftec.csv')\n",
    "#print(dftec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MADE GEOJSON WITH YOH\n",
    "df.to_file(\"dftec.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def charge_ellipse(charge=df.grp_description.unique().tolist()):\n",
    "    # filter the data by race\n",
    "    charge_filtered = df[df.grp_description == charge]\n",
    "\n",
    "    # mean center and median\n",
    "    mean_center = centrography.mean_center(charge_filtered[['x','y']])\n",
    "    med_center = centrography.euclidean_median(charge_filtered[['x','y']])\n",
    "\n",
    "    # standard ellipse\n",
    "    major, minor, rotation = centrography.ellipse(charge_filtered[['x','y']])\n",
    "\n",
    "    # Set up figure and axis\n",
    "    f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "\n",
    "    # plot arrest points\n",
    "    ax.scatter(charge_filtered['x'], charge_filtered['y'], s=0.75)\n",
    "\n",
    "    # add the mean and median center points\n",
    "    ax.scatter(*mean_center, color='red', marker='x', label='Mean Center')\n",
    "    ax.scatter(*med_center, color='limegreen', marker='o', label='Median Center')\n",
    "\n",
    "    # heatmap\n",
    "    sns.kdeplot(x = charge_filtered.geometry.x, \n",
    "                y = charge_filtered.geometry.y,\n",
    "                n_levels=20, \n",
    "                shade=False,\n",
    "                thresh=0.1,\n",
    "                alpha=0.3, \n",
    "                cmap='Reds', \n",
    "                ax=ax)\n",
    "\n",
    "    # Construct the standard ellipse using matplotlib\n",
    "    ellipse = Ellipse(xy=mean_center, # center the ellipse on our mean center\n",
    "                      width=major*2, # centrography.ellipse db_filtered\n",
    "                      height=minor*2, \n",
    "                      angle = numpy.rad2deg(rotation), # Angles for this are in degrees, not radians\n",
    "                      facecolor='none', \n",
    "                      edgecolor='red', linestyle='--',\n",
    "                      label='Std. Ellipse')\n",
    "\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.axis('Off')\n",
    "\n",
    "    ax.set_title(str(len(charge_filtered)) + ' incidents of crime with reported victim descent \"' + crime + '\"') #CHANGE HERE\n",
    "\n",
    "    # add a basemap\n",
    "    ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter)\n",
    "    # Display\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap displays the concentration of arrests with the median center and mean center. Although lacking the basemap, the image describes which areas could be more affected by the concentrations of crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to crs \n",
    "df=df.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert floats\n",
    "df.lon = df.lon.astype('float')\n",
    "df.lat = df.lat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot concentrations on map with base\n",
    "ax= df.plot(figsize=(12,12),\n",
    "            color='red',\n",
    "            markersize=1)\n",
    "            \n",
    "ax.axis('off')\n",
    "            \n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find bounds\n",
    "minx, miny, maxx, maxy = df.geometry.total_bounds\n",
    "print(minx)\n",
    "print(maxx)\n",
    "print(miny)\n",
    "print(maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS WHERE WE START EXPLORATION FOR OPTION 1\n",
    "#we are attempting to start the spatial auto correlation for our final :)\n",
    "map_arrests_by_type.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make gdf from df\n",
    "gdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index to include counts\n",
    "arrests_by_gdf = gdf.FIPS.value_counts().rename_axis('FIPS').reset_index(name='arrests_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests_by_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge arrests by FIPS to find the arrest counts to see the average in each FIPS by hazscore- this is where we got stuck with the ratio\n",
    "gdf=gdf.merge(arrests_by_gdf,on='FIPS')\n",
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#describe arrests per FIPS\n",
    "arrests_by_gdf[:30].plot.bar(figsize=(20,4),\n",
    "                             x='FIPS',\n",
    "                             y='arrests_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gdf.merge(arrests_by_gdf,on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could run inso problems with crs left and right not matching, but I did an override\n",
    "df.crs\n",
    "df.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointInPoly = gpd.sjoin(tracts_ejsm, df, how='right')\n",
    "pointInPoly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join counts- need to get counts by FIPS for ratio\n",
    "crime_ct=join.FIPS_x.value_counts().rename_axis(\"FIPS_x\").reset_index(FIPS_x=\"crime_count\")\n",
    "crime_ct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need count\n",
    "gdf['arrests_per_HazScore'] = gdf['arrests_count']/gdf['Hazscore']*100\n",
    "gdf.sort_values(by=\"arrests_per_HazScore\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gdf of arrests by hazscore ratio\n",
    "#gdf['arrests_per_HazScore'] = gdf['arrests_count']/gdf['HazScore']*100\n",
    "#gdf.sort_values(by=\"arrests_per_HazScore\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests[arrests.lon==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE IS THE READ MISSING UNAMED\n",
    "\n",
    "#dftec=pd.read_csv(\n",
    "#'Mangonadas\\Data\\dftec.csv')\n",
    "#print(dftec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of labor:\n",
    "AG: fixed the sample size of data and did explorations with the heatmap and KDE plot\n",
    "DH:seaborn maps and data exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
